{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State machine like implementation for grasping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlbench.environment import Environment\n",
    "from rlbench.action_modes import ArmActionMode, ActionMode\n",
    "from rlbench.observation_config import ObservationConfig\n",
    "from rlbench.tasks import *\n",
    "import numpy as np\n",
    "from pyrep.const import ConfigurationPathAlgorithms as Algos\n",
    "import scipy as sp\n",
    "from quaternion import from_rotation_matrix, quaternion\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(x):\n",
    "    return np.array([[0, -x[2], x[1]],\n",
    "                    [x[2], 0, -x[0]],\n",
    "                    [-x[1], x[0], 0]])\n",
    "\n",
    "\n",
    "def sample_normal_pose(pos_scale, rot_scale):\n",
    "    '''\n",
    "    Samples a 6D pose from a zero-mean isotropic normal distribution\n",
    "    '''\n",
    "    pos = np.random.normal(scale=pos_scale)\n",
    "        \n",
    "    eps = skew(np.random.normal(scale=rot_scale))\n",
    "    R = sp.linalg.expm(eps)\n",
    "    quat_wxyz = from_rotation_matrix(R)\n",
    "\n",
    "    return pos, quat_wxyz\n",
    "\n",
    "\n",
    "class RandomAgent:\n",
    "\n",
    "    def act(self, obs):\n",
    "        delta_pos = [(np.random.rand() * 2 - 1) * 0.005, 0, 0]\n",
    "        delta_quat = [0, 0, 0, 1] # xyzw\n",
    "        gripper_pos = [np.random.rand() > 0.5]\n",
    "        return delta_pos + delta_quat + gripper_pos\n",
    "\n",
    "\n",
    "class NoisyObjectPoseSensor:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "\n",
    "        self._pos_scale = [0.005, 0.005, 0.005]\n",
    "        self._rot_scale = [0.01] * 3\n",
    "\n",
    "    def get_poses(self):\n",
    "        objs = self._env._scene._active_task.get_base().get_objects_in_tree(exclude_base=True, first_generation_only=False)\n",
    "        obj_poses = {}\n",
    "\n",
    "        for obj in objs:\n",
    "            name = obj.get_name()\n",
    "            pose = obj.get_pose()\n",
    "\n",
    "            pos, quat_wxyz = sample_normal_pose(self._pos_scale, self._rot_scale)\n",
    "            gt_quat_wxyz = quaternion(pose[6], pose[3], pose[4], pose[5])\n",
    "            perturbed_quat_wxyz = quat_wxyz * gt_quat_wxyz\n",
    "\n",
    "            pose[:3] += pos\n",
    "            pose[3:] = [perturbed_quat_wxyz.x, perturbed_quat_wxyz.y, perturbed_quat_wxyz.z, perturbed_quat_wxyz.w]\n",
    "\n",
    "            obj_poses[name] = pose\n",
    "\n",
    "        return obj_poses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(r1, r2):\n",
    "    #whether r2 is within r1\n",
    "    return r1[0] < r2[0] < r2[1] < r1[1] and r1[2] < r2[2] < r2[3] < r1[3] and r1[4] < r2[4] < r2[5] < r1[5]\n",
    "\n",
    "def get_edge_points(obj_bbox,obj_mat):\n",
    "    bbox_faceedge=np.array([[obj_bbox[0],0,0],\n",
    "    [obj_bbox[1],0,0],\n",
    "    [0,obj_bbox[2],0],\n",
    "    [0,obj_bbox[3],0],\n",
    "    [0,0,obj_bbox[4]],\n",
    "    [0,0,obj_bbox[5]]]).T #3x6\n",
    "    bbox_faceedge=np.vstack((bbox_faceedge,np.ones((1,6)))) #4x6\n",
    "    box=(obj_mat@bbox_faceedge).T #6X3 face edge coords in world frame\n",
    "    rect=min(box[:,0]),max(box[:,0]),min(box[:,1]),max(box[:,1]),min(box[:,2]),max(box[:,2]) #max/min along x,y,z world axes\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMachine(object):\n",
    "    def __init__(self):\n",
    "        self.env=None\n",
    "        self.home=None\n",
    "        self.task=None\n",
    "        self.sensor=None\n",
    "        self.objs_dict=None\n",
    "        \n",
    "    def initialize(self):\n",
    "        DATASET = ''\n",
    "        obs_config = ObservationConfig()\n",
    "        obs_config.set_all(True)\n",
    "        obs_config.left_shoulder_camera.rgb = True\n",
    "        obs_config.right_shoulder_camera.rgb = True\n",
    "        action_mode = ActionMode(ArmActionMode.DELTA_EE_POSE)\n",
    "        self.env = Environment(\n",
    "            action_mode, DATASET, obs_config, False)\n",
    "        self.sensor = NoisyObjectPoseSensor(self.env)\n",
    "        self.env.launch()\n",
    "        self.task = self.env.get_task(EmptyContainer)\n",
    "        self.task.reset()\n",
    "        self.home = self.get_objects()['large_container'].get_pose()\n",
    "        self.home[2]+=0.3\n",
    "        # demos = task.get_demos(3, live_demos=live_demos)\n",
    "        \n",
    "    def get_objects(self):\n",
    "        objs = self.env._scene._active_task.get_base().get_objects_in_tree(exclude_base=True, first_generation_only=False)\n",
    "        objs_dict = {}\n",
    "        for obj in objs:\n",
    "            name = obj.get_name()\n",
    "            pose = obj.get_pose()\n",
    "            objs_dict[name] = obj\n",
    "        return objs_dict\n",
    "\n",
    "    # Move above object\n",
    "    def move_to(self, pose, pad=0.05, ignore_collisions=True):\n",
    "        target_pose = np.copy(pose)\n",
    "        obs = self.env._scene.get_observation()\n",
    "        init_pose=obs.gripper_pose\n",
    "        obs = self.env._scene.get_observation()\n",
    "        init_pose=obs.gripper_pose\n",
    "        target_pose[2]+=pad\n",
    "        path=self.env._robot.arm.get_path(np.array(target_pose[0:3]),quaternion=np.array([0,1,0,0]), trials=1000,ignore_collisions=True, algorithm=Algos.RRTConnect)\n",
    "        # TODO catch errors and deal with situations when path not found\n",
    "        return path\n",
    "    \n",
    "    def grasp(self,obj):\n",
    "        # TODO get feedback to check if grasp is successful\n",
    "        cond=False\n",
    "        while not cond:\n",
    "            cond=self.env._robot.gripper.actuate(0,0.1)\n",
    "            self.env._scene.step()\n",
    "        cond = self.env._robot.gripper.grasp(obj)\n",
    "        return cond\n",
    "    \n",
    "    def release(self, obj):\n",
    "        cond=False\n",
    "        while not cond:\n",
    "            cond=self.env._robot.gripper.actuate(1,0.1)\n",
    "            self.env._scene.step()\n",
    "        self.env._robot.gripper.release()\n",
    "    \n",
    "    def execute(self, path):\n",
    "        done=False\n",
    "        path.set_to_start()\n",
    "        while not done:\n",
    "            done = path.step()\n",
    "            a = path.visualize()\n",
    "            self.env._scene.step()\n",
    "        return done\n",
    "    \n",
    "    def reset(self):\n",
    "        self.task.reset()\n",
    "    \n",
    "    \n",
    "    def is_within(self,obj1,obj2):\n",
    "        #whether obj2 is within obj1\n",
    "        obj1_bbox=obj1.get_bounding_box();obj1_mat=np.array(obj1.get_matrix()).reshape(3,4);\n",
    "        obj2_bbox=obj2.get_bounding_box();obj2_mat=np.array(obj2.get_matrix()).reshape(3,4);\n",
    "        obj1_rect= get_edge_points(obj1_bbox,obj1_mat)\n",
    "        obj2_rect= get_edge_points(obj2_bbox,obj2_mat)\n",
    "        return contains(obj1_rect,obj2_rect)\n",
    "    \n",
    "    def picking_bin_empty(self):\n",
    "        '''\n",
    "         Returns whether the picking bin is empty\n",
    "        '''\n",
    "        self.objs_dict=machine.get_objects()\n",
    "        bin_obj=self.objs_dict['large_container'] #?Which one\n",
    "        for obj_name in self.objs_dict.keys():\n",
    "            if (not ('container' in obj_name)):\n",
    "                if self.is_within(bin_obj,self.objs_dict[obj_name]):\n",
    "                    return False\n",
    "        return True\n",
    "    def placing_bin_full(self):\n",
    "        '''\n",
    "         Returns whether the placing bin is full\n",
    "        '''\n",
    "        self.objs_dict=machine.get_objects()\n",
    "        bin_obj=self.objs_dict['small_container1'] #?Which one\n",
    "        for obj_name in self.objs_dict.keys():\n",
    "            if (not ('container' in obj_name)):\n",
    "                if not (self.is_within(bin_obj,self.objs_dict[obj_name])):\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arcot/.local/lib/python3.7/site-packages/pyrep/pyrep.py:209: UserWarning: Could not change simulation timestep. You may need to change it to \"custom dt\" using simulation settings dialog.\n",
      "  warnings.warn('Could not change simulation timestep. You may need '\n"
     ]
    }
   ],
   "source": [
    "# env, task, obs = init()\n",
    "machine = StateMachine()\n",
    "machine.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine.reset()\n",
    "objects = ['Shape', 'Shape1', 'Shape3']\n",
    "for shape in objects:\n",
    "    # move above object\n",
    "    objs=machine.get_objects()\n",
    "    objs_poses=machine.sensor.get_poses()\n",
    "    # pose=objs[shape].get_pose()\n",
    "    pose=objs_poses[shape]\n",
    "    path=machine.move_to(pose,False)\n",
    "    machine.execute(path)\n",
    "\n",
    "    # grasp the object\n",
    "    cond = machine.grasp(objs[shape])\n",
    "\n",
    "    # move to home position\n",
    "    path=machine.move_to(machine.home, 0, True)\n",
    "    machine.execute(path)\n",
    "\n",
    "    # move above small container\n",
    "    objs_poses=machine.sensor.get_poses()\n",
    "    pose = objs_poses['small_container0']\n",
    "    path=machine.move_to(pose,0.05,True)\n",
    "    machine.execute(path)\n",
    "\n",
    "    # release the object\n",
    "    machine.release(objs[shape])\n",
    "\n",
    "    # go back to home position\n",
    "    path=machine.move_to(machine.home,0,True)\n",
    "    machine.execute(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013230234384536743,\n",
       " 0.013230234384536743,\n",
       " -0.022011950612068176,\n",
       " 0.022011950612068176,\n",
       " -0.04769759625196457,\n",
       " 0.04769759625196457]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs_dict=machine.get_objects()\n",
    "obj_pose=objs_dict['Shape'].get_pose()\n",
    "obj_pose=np.repeat(obj_pose,2)\n",
    "objs_dict['Shape'].get_bounding_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'machine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fb2e29d93732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpicking_bin_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'machine' is not defined"
     ]
    }
   ],
   "source": [
    "machine.picking_bin_empty()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arcot/.local/lib/python3.7/site-packages/pyrep/pyrep.py:209: UserWarning: Could not change simulation timestep. You may need to change it to \"custom dt\" using simulation settings dialog.\n",
      "  warnings.warn('Could not change simulation timestep. You may need '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['put the crackers in the cupboard',\n",
       "  'pick up the crackers and place it in the cupboard',\n",
       "  'move the crackers to the bottom shelf',\n",
       "  'put away the crackers in the cupboard'],\n",
       " <rlbench.backend.observation.Observation at 0x7fdd058467b8>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rlbench.environment import Environment\n",
    "from rlbench.action_modes import ArmActionMode, ActionMode\n",
    "from rlbench.observation_config import ObservationConfig\n",
    "from rlbench.tasks import *\n",
    "import numpy as np\n",
    "from pyrep.const import ConfigurationPathAlgorithms as Algos\n",
    "import scipy as sp\n",
    "from quaternion import from_rotation_matrix, quaternion\n",
    "DATASET = ''\n",
    "obs_config = ObservationConfig()\n",
    "obs_config.set_all(True)\n",
    "obs_config.left_shoulder_camera.rgb = True\n",
    "obs_config.right_shoulder_camera.rgb = True\n",
    "action_mode = ActionMode(ArmActionMode.DELTA_EE_POSE)\n",
    "env = Environment(\n",
    "    action_mode, DATASET, obs_config, False)\n",
    "env.launch()\n",
    "task = env.get_task(PutGroceriesInCupboard)\n",
    "task.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = env._scene._active_task.get_base().get_objects_in_tree(exclude_base=True, first_generation_only=False)\n",
    "objs_dict = {}\n",
    "for obj in objs:\n",
    "    name = obj.get_name()\n",
    "    pose = obj.get_pose()\n",
    "    objs_dict[name] = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chocolate_jello': <pyrep.objects.shape.Shape at 0x7fdd452cedd8>,\n",
       " 'strawberry_jello': <pyrep.objects.shape.Shape at 0x7fdd164f9b70>,\n",
       " 'soup': <pyrep.objects.shape.Shape at 0x7fdd449e50b8>,\n",
       " 'tuna': <pyrep.objects.shape.Shape at 0x7fdd449e50f0>,\n",
       " 'spam': <pyrep.objects.shape.Shape at 0x7fdd449e5128>,\n",
       " 'sugar': <pyrep.objects.shape.Shape at 0x7fdd449e5160>,\n",
       " 'coffee': <pyrep.objects.shape.Shape at 0x7fdd449e51d0>,\n",
       " 'crackers': <pyrep.objects.shape.Shape at 0x7fdd449e5080>,\n",
       " 'mustard': <pyrep.objects.shape.Shape at 0x7fdd449e5208>,\n",
       " 'waypoint1': <pyrep.objects.dummy.Dummy at 0x7fdd449e5278>,\n",
       " 'boundary_root': <pyrep.objects.shape.Shape at 0x7fdd449e5240>,\n",
       " 'chocolate_jello_visual': <pyrep.objects.shape.Shape at 0x7fdd449e5198>,\n",
       " 'chocolate_jello_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd449e52b0>,\n",
       " 'strawberry_jello_visual': <pyrep.objects.shape.Shape at 0x7fdd449e52e8>,\n",
       " 'strawberry_jello_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd449e5320>,\n",
       " 'soup_visual': <pyrep.objects.shape.Shape at 0x7fdd449e5358>,\n",
       " 'soup_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd449e5390>,\n",
       " 'tuna_visual': <pyrep.objects.shape.Shape at 0x7fdd058468d0>,\n",
       " 'tuna_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846b38>,\n",
       " 'spam_visual': <pyrep.objects.shape.Shape at 0x7fdd05846d68>,\n",
       " 'spam_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846e48>,\n",
       " 'sugar_visual': <pyrep.objects.shape.Shape at 0x7fdd05846b00>,\n",
       " 'sugar_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846da0>,\n",
       " 'coffee_visual': <pyrep.objects.shape.Shape at 0x7fdd05846b70>,\n",
       " 'coffee_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846ba8>,\n",
       " 'crackers_visual': <pyrep.objects.shape.Shape at 0x7fdd05846be0>,\n",
       " 'crackers_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846c18>,\n",
       " 'mustard_visual': <pyrep.objects.shape.Shape at 0x7fdd05846c50>,\n",
       " 'mustard_grasp_point': <pyrep.objects.dummy.Dummy at 0x7fdd05846c88>,\n",
       " 'waypoint2': <pyrep.objects.dummy.Dummy at 0x7fdd05846cc0>,\n",
       " 'waypoint0': <pyrep.objects.dummy.Dummy at 0x7fdd05846cf8>,\n",
       " 'cupboard': <pyrep.objects.shape.Shape at 0x7fdd05846dd8>,\n",
       " 'waypoint3': <pyrep.objects.dummy.Dummy at 0x7fdd05846e10>,\n",
       " 'success': <pyrep.objects.proximity_sensor.ProximitySensor at 0x7fdd05846e80>,\n",
       " 'waypoint4': <pyrep.objects.dummy.Dummy at 0x7fdd05846d30>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
